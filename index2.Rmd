---
title: 'Pesquisa [R]eproduzível'
output:
  html_document:
    css: style.css
    df_print: paged
    theme: flatly
    highlight: default
    toc: true
    toc_float: 
     collapsed: false
     smooth_scroll: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Definições

A Pesquisa Reproduzível (PR) tem a ver com reprodutibilidade da pesquisa, que pode ser definida como:

> *A habilidade de um pesquisador em obter os resultados de um estudo prévio usando os mesmos materiais (dados) e métodos (estatística) da pesquisa original*.

Logicamente, uma condição essencial para que isso seja possível é que o pesquisador independente tenha acesso aos dados e todos os detalhes de como e porque a análise foi feita de uma determinada maneira. Em ciência, essa deve ser uma condição mínima necessária para que um resultado seja acreditado e informativo. Parte-se do princípio que os resultados de uma pesquisa publicados em revistas científicas com corpo editorial foram obtidos segundo os princípios e métodos científicos. No entanto, os editores e revisores, na maioria das vezes, não tem como verificar se todos os passos foram executados corretamente, já que recebem apenas o "produto final" da final, o qual deve conter as informações mínimas necessárias para que o trabalho seja avaliado. 

O termo reprodutibilidade é bastante atual e pode ter várias definições dependendo do contexto. Nos ateremos ao caso de matérias na mídia acadêmica que comentam sobre a atual **crise de reprodutibilidade na ciência** a qual é reconhecida principalmente pelos pesquisadores. O que seria esse fenômeno? A tal crise se refere a um tipo de reprodutibilidade que é a **inferencial**, também chamada de **replicabilidade**, ou seja,a capacidade de obte um mesmo resultado ou conclusão de uma pesquisa anterior com a condução de uma nova pesquisa, ou seja, novos dados obtidos para responder uma mesma questão. 

A chamada crise de reprodutibilidade está associada aos casos não tão incomuns de experimentos (área farmacêutica, por exemplo) que são conduzidos para avaliar a eficácia de algum produto e, que, por algum motivo, novos experimentos não confirmam os resultados anteriores. Há muita discussão sobre as possíveis causas dessa falta de "replicabilidade", incluindo-se aspectos relacinados à viés seletivo, métodos estatísticos inapropriados, bem como uma falta de maior transparência sobre os dados e o processo analítico.

No contexto em que iremos trabalhar, a pesquisa reproduzível (PR), assumindo os mesmos dados e procedimentos, apresenta inúmeras vantagens como dar transparência e confiabilidade à análise, além de permitir que se detectem erros de análise, o que não é incomum. Ela não resolve o problema de replicabilidade já que problemas de deficiência ou equívocos em dados ou análise, ou mesmo má conduta científica, podem ocorrer. No entanto é reconhecido que o uso de boas práticas de PR visam a atender essa demanda por maior transparência na pesquisa. Além disso, permite que os dados gerados pelos pesquisadores não fiquem "engavetados" mas que possam ser reusados ou reanalisados. Atualmente, agências de fomento e a comunidade científia tem exigido ou estimulado que dados e códigos sejam cada vez mais compartilhados e novas ferramentas tem surgido para facilitar esse processo e permitir que pesquisadores obtenham crédito e reconhecimento.


## Um projeto reproduzível

Para um estudante ou cientista que está iniciando um projeto é importante que as boas práticas de PR sejam incorporadas no seu dia a dia, e que sejam implementadas desde a concepção e o planejamento do mesmo. 

São atividades que dependem essencialmente de uma grande capacidade organizacional e admistrativa de tempo e esforço no planejamento, condução e documentação de tudo que é feito. É preciso seguir rotinas e gerar documentos que seguem certas normas de padronização, especialmente se o trabalho é feito de forma colaborativa. Analogamente, é como escrever e formatar um artigo científico que deve ser estruturado e apresentado segundo determinadas normas. Aqui, o produto gerado não é somente o documento do manuscrito e um punhado de gráficos, mas sim tudo que foi gerado durante a pesquisa e que precisa estar bem organizado e formatado para uso posterior e publicação/divulgação. Para obter sucesso na implementação de uma PR, é preciso:

- Ser diligente e sistemático 
- Aprender novas ferramentas (computacionais)
- Aprender a organizar arquivos diversos 
- Documentar todas as etapas do trabalho

No dia a dia, os pesquisadores não sobrevivem se os computadores como ferramenta central de trabalho. Atualmente, não é preciso ser um "nerd" para que se possa utilizar com bastante eficiência os computadores que estão  hoje cada vez mais portáteis e de fácil uso, para ser eficiente e produtivo no trabalho. Em algumas áreas da pesquisa é necessário maior envolvimento com linguagens de programação, programas específicos que exigem um esforço de aprendizado. 

No entanto, na PR o mais importante e desafior é certamente aprender a sistemática de trabalho do que ser um expert em programação - mas é necessário sim aprender alguma linguagem de programação (R ou Python) para implementar as práticas de PR. Durante nossa formação acadêmica não recebemos nenhum ou muito pouco treinamento em como preparar e organizar de maneira apropriadas os arquivos diversos incluindo dados, códigos, gráficos, tabelas, manuscrito, figuras, etc. 

Apender uma rotina de PR é fundamental para:

1) Facilitar o nosso próprio trabalho de análise-reanálise
2) Permitir o uso dos dados e códigos por outras pessoas (seu orientador!)
3) Compartilhar a "pipeline" da análise, ou seja, explicar o que, por que e como foi feito

Quando não somos treinados a trabalhar seguindo as boas práticas de PR, é muito comum: criar um número grande arquivos e versões desnecessárias que dificultam o processo; gerar inconsistência e redundância nas análises; não ter um controle adequado de versões e dificuldade quando é solicitado o compartilhamento do trabalhos - ou seja, levará um tempo grande só para organizar a "bagunça" que foi gerada durante o processo e que só o próprio pesquisador entende, quando entende! Práticas que deveriam ser simples como refazer um gráfico ou estatísticas após receber os pareceres de revisores se tornam um verdadeiro pesadelo para alguns pesquisadores, o que contribui para o atraso na publicação de artigos.


## Ferramentas 

Segundo [Yihui Xie](https://yihui.name), um dos principais desenvolvedores do R da empresa RStudio de programas (ex. knitr, rMarkdown, bookdown, etc) que visam facilitar a pesquisa reproduzível:

>The final product of research is not only the paper itself, but also the full computation environment used to produce the results in the paper such as the code and data necessary for reproduction of the results and building upon the research (Xie et al. 2014).

Dentre os ambientes de programação disponíveis, as ferramentas mais usadas para implementar uma PR de maneira efetiva (dados, análises e saídas são combinados, idealmente, em um único ambiente de programação), são baseados em duas linguagens principais: Python e R, cujos produtos principais são Jupyter Notebooks e RMarkdown, respectivamente. Esses pacotes ou rotinas facilitam sobremaneira a documentação e reprodução das análises bem como aceleram a obtenção dos resultados e visualizações assim que novos dados forem adicionados ou reanálises são necessárias. 

Além de aprender a utilizar esses programas, é importante que o pesquisador aprenda como usar efetivamente planilhas eletrônicas para reunir e organizar os dados que serão usados na pesquisa. Por princípios, as planilhas eletrônicas como Excel, Libre Office Calc, Numbers e Google Sheets são usadas apenas para armazenar os dados e não para processar, transformar, visualizar ou fazer sumários prévios. O motivo é muito simples: esses procedimentos todos feitos com movimentos de mouse não são reproduzíveis! além disso, na PR os dados originais levantados ou recebidos devem ser mantidos na sua forma original. Caso seja modificado de forma que é mais fácil fazer em uma planilha como renomear variáveis, é importante manter sempre uma planilha não manipulada como referência. 


## Compendium da pesquisa

O termo compêndio de pesquisa ([Research Compendia](https://github.com/ropensci/rrrpkg) foi cunhado em meados dos anos 90.

> We introduce the concept of a compendium as both a container for the different elements that make up the document and its computations (i.e. text, code, data,...), and as a means for distributing, managing and updating the collection. - Gentleman, R. and Temple Lang, D. (2004)

O compêndio nada mais é do que um método padronizado e facilmente reconhecido de organizar os materiais digitais de um projeto de pesquisa para que outros possam inspecionar, reproduzir e ampliar a pesquisa. Princípios básicos são:

1) Organizar segundo a convenção criada pela academia
2) Separar claramente os dados, os métodos e as saídas
3) Especificar o ambiente computacional usado na análise (texto com a descrição, versão, etc)

O objetivo de criar um compêndio de pesquisa é para facilitar a distribuição dos produtos gerados pela pesquisa. Além disso, a eficiência do trabalho é aumentada com a incorporação de uma sistemática que pode ser replicada em outros projetos, dimuindo assim os custos operacionais e acelerando o trabalho. Tem se discutido que publicações que são acompanhas de um compêndio tendem a receber maior atenção, credibilidade e citações uma vez que o compendio é uma publicação separada. Certamente, quando publicada anteriormente à submissão do trabalho, os editores e revisores terão um trabalho muito mais facilitado para revisar os métodos (estatísticos principalmente) que foram utilizados e entender as decisões tomadas no processo analítico. Alem disso, autores poderão receber um retorno da acadêmica e dos revisores para melhorarem o trabalho como um todo.

Antes de falarmos sobre como organizar o compêndio de pesquisa, veremos aspectos e cuidados específicos de organização dos dados.

## Dados

Segundo Wilkinson et al. (2016), os dados devem ser organizados segundo o princípio **FAIR** = **F**indable, **A**ccessible, **I**nteroperable and **R**eusable. 

Compartilhar os dados (o que pode ser aplicado também aos códigos, significa facilitar a distribuição e o acesso pela comunidade científica, ou seja que eles sejam facilmente **encontrados** e **acessados**. Qual a vantagem disso? reproduzir os resultados originais e pertimitir que novas análises sejam feitas usando os mesmos dados, ou mesmo combinando com outros conjuntos de dados (metanálise). É importante que os dados estejam em um formato que seja de fácil entendimento para facilitar o uso. Três boas práticas são recomendadas:
 
1. Documentação: dados bem documentados e descritos (metadados) são mais fáceis de entender
2. Formataçao: dados formatados apropriadamente podem ser usados em diversos programas de computador
3. Distribuição: depósito em repositórios conhecidos e com licença aberta facilita que sejam encontrados e reusados

Práticas de compartilhamento de dados talvez ainda não sejam valorizadas pela maioria dos pesquisadores, haja visto que a maioria dos trabalhos ainda não disponibilizam os dados originais. As vantagens óbvias seria a reprodução e possível melhorias na análise, o reuso dos dados em metanálises para chegar a conclusões gerais e gerar novo conhecimento que só é possível com dados compartilhados em larga escala. Mas por que ainda os pesquisadores não compartilham os dados? os motivos podem ser ligados ao receio de perder uma competição por publicações ou mesmo a falta de conhecimento sobre como fazer o compartilhamento. A percepção que domina é que organizar e depositar dados é difícil tecnicamente ou leva muito tempo,

### Metadados

O que são os metadados?
Information about the data, including how it was collected, what the units of measurement are, and descriptions of how to best use the data 

- The what, when, where, and how of data collection.
- How to find and access the data.
- Suggestions on the suitability of the data for ans-
wering specific questions.
- Warnings about known problems or inconsistencies in the data, e.g., general descriptions of data limitations or a column in a table to indicate the quality of individual data points.
- Information to check that the data are properly imported, e.g., the number of rows and columns in the dataset and the total sum of numerical columns.

The easiest way to develop metadata is to start describing your data during the planning and data collection stages. This will help you stay organized, make it easier to work with your data after it has been collected, and make eventual publication of the data easier. 

Raw (unprocessed) data

Often, the data used in scientific analyses are mod- ified in some way from the original form in which they were collected. Values are averaged, units are convert- ed, or indices are calculated from direct measurements or observations to address the focal research questions and to fix issues associated with the raw data. 

That means providing your data in a form that is as close as possible to the field measurements and observations from which your analysis started.

Providing both the raw and processed forms of the data, and clearly explaining the differences between them in the metadata, is an easy way to include the benefits of both data forms. An alternate approach is to share the unprocessed data along with the code that processes the data to the form you used for analysis. This allows other scientists to assess and potentially modify the process by which you arrived at the values used in your analysis.




### Formato

Data tables are ubiquitous in ecology and evolution. Tabular data provides a great deal of flexibility in how data can be structured. However, this flexibility also makes it easy to structure your data in a way that is difficult to (re)use.

- Each row should represent a single observation (i.e., record) and each column should represent a single variable or type of measurement 
- Every cell should contain only a single value (Strasser et al. 2012). For example, do not include units in the cell with the values
- There should be only one column for each type of information


 Standard format within cells

- Be consistent. For example, be consistent in your capitalization of words, choice of delimiters, and naming conventions for variables.
- Avoid special characters. Most software for storing and analyzing data works best on plain text, and accents and other special characters can make it difficult to import your data (Borer et al. 2009, Strasser et al. 2012).
- Avoid using your delimiter in the data itself (e.g., commas in the notes filed of a comma-delimited file). This can make it difficult to import your data properly. This means that if you are using commas as the decimal separator (as is often done in continental Europe) then you should use a non- comma delimiter (e.g., a tab).
-  When working with dates use the YYYY-MM-DD format (i.e., follow the ISO 8601 data standard).

Use consistent codes for categorical variables. For a categorical variable like the sex of a mouse in a genetics study, use a single common value for males (e.g. “male”) and a single common value for females (e.g. “female”). Don’t sometimes write “M”, sometimes “male”, and sometimes “Male”. Pick one and stick to it.

Use consistent variable names. If in one file (for example, the first batch of subjects), you have a variable called “Glucose 10wk”, then call it exactly that in other files (for example, for other batches of subjects). If it is variably called “Glucose 10wk”, “gluc 10weeks”, and “10 week glucose”, then downstream the data analyst will have to work out that these are all really the same thing.

Use consistent file names. Have some system for naming files. If one file is called
“Serum batch1 2015-01-30.csv”, then don’t call the file for the next batch “batch2 serum 52915.csv” but rather use “Serum batch2 2015-05-29.csv”. Keeping a consistent file naming scheme
will help ensure that your files remain well organized, and it will make it easier to batch
process the files if you need to.


Use a consistent format for all dates, preferably with the standard format YYYY-MM-DD, for example 2015-08-01. If sometimes you write 8/1/2015 and sometimes 8-1-15, it will be more difficult to use the dates in analyses or data visualizations.

When entering dates, we strongly recommend using the global “ISO 8601” standard, YYYY-MM-DD, such as 2013-02-27. (See the related xkcd comic, https://xkcd.com/1179.) Microsoft Excel’s treatment of dates can cause problems in data (see https://storify. com/kara_woo/excel-date-system-fiasco). It stores them internally as a number, with different conventions on Windows and Macs. So, you may need to manually check the
integrity of your data when they come out of Excel.

We often prefer to use a plain text format for columns in an Excel worksheet that are going to contain dates, so that it doesn’t do anything to them. To do this:
• Select the column
• In the menu bar, select Format → Cells • Choose “Text” on the left



Use consistent phrases in your notes. If you have a separate column of notes (for example, “dead” or “lo off curve”), be consistent in what you write. Don’t sometimes write “dead” and sometimes “Dead”, or sometimes “lo off curve” and sometimes “off curve lo”.

Be careful about extra spaces within cells. A blank cell is different than a cell that contains a single space. And “male” is different from “ male ” (that is, with spaces at the beginning and end).



### Planilhas eletronicas


- be consistent
- write dates like YYYY-MM-DD
- don’t leave any cells empty
- put just one thing in a cell
- organize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row
- create a data dictionary
- don’t include calculations in the raw data files,
- don’t use font color or highlighting as data, 
- choose good names for things, 
- make backups, 
- use data validation to avoid data entry errors, 
- and save the data in plain text file.



Spreadsheets are often used as a multipurpose tool for data entry, storage, analysis, and visualization. Most spreadsheet programs allow users to perform all of these tasks, however we believe that spreadsheets are best suited to data entry and storage, and that analysis and visualization should happen separately. Analyzing and visualizing data in a separate program, or at least in a separate copy of the data file, reduces the risk of contaminating or destroying the raw data in the spreadsheet.

re- searchers will create spreadsheets that are less error-prone, easier for computers to process, and easier to share with collaborators and the public. Spreadsheets that adhere to our recommendations will work well with the tidy tools and reproducible methods described elsewhere in this collection and will form the basis of a robust and reproducible analytic workflow.

No calculations in the raw data files

Often, the Excel files that our collaborators send us include all kinds of calculations and graphs. We feel strongly that your primary data file should contain just the data and nothing else: no calculations, no graphs.
If you are doing calculations in your data file, that likely means you are regularly opening it and typing into it. Doing so incurs some risk that you will accidentally type junk into your data.
(Has this happened to you? You open an Excel file and start typing and nothing happens, and then you select a cell and you can start typing. Where did all of that initial text go? Well, sometimes it got entered into some random cell, to be discovered later during data analysis.)
Your primary data file should be a pristine store of data. Write-protect it, back it up, and don’t touch it.
If you want to do some analyses in Excel, make a copy of the file and do your calculations and graphs in the copy.



### Nomes

As a general rule, don’t use spaces, either in variable names or file names. They make programming harder: the analyst will need to surround everything in double quotes, like "glucose 6 weeks", rather than just writing glucose 6 weeks. Where you might use spaces, use underscores or perhaps hyphens.

The main principle in choosing names, whether for variables or for file names, is short, but meaningful. So not too short. The Data Carpentry lesson on using spreadsheets (see http://www.datacarpentry.org/spreadsheet-ecology-lesson/02-common-mistakes) has a nice table with good and bad example variable names, reproduced in Table 1. We agree with all of this, though we would maybe cut down on some of the capitalization. So maybe max temp, precipitation, and mean year growth.
Finally, never include “final” in a file name. You will invariably end up with “final ver2”. (We can’t say that without referring to the widely-cited PhD comic, http://bit.ly/ phdcom_final.)

Create a data dictionary

It is helpful to have a separate file that explains what all of the variables are. It is helpful if this is laid out in rectangular form, so that the data analyst can make use of it in analyses.
Such a “data dictionary” might contain:
- The exact variable name as in the data file
- A version of the variable name that might be used in data visualizations
- A longer explanation of what the variable means
- The measurement units
- Expected minimum and maximum values

This is part of the metadata that you will want to prepare: information about the data. You will also want a ReadMe file that includes an overview of the project and data.


 Faltantes

null --> blank cell or NA

Use a consistent fixed code for any missing values. We prefer to have every cell filled in, so that one can distinguish between truly missing values and unintentionally missing values. R users prefer “NA”. You could also use a hyphen. But stick with a single value throughout. Definitely don’t use a numeric value like -999 or 999; it is easy to miss that it is intended to be missing. Also, don’t insert a note in place of the data, explaining why it is missing. Rather, make a separate column with such notes.

Nomes de lugares, espécies, etc evitar o uso de abreviações que só o pesquisador conhece

### Copias

Make regular backups of your data. In multiple locations. And consider using a formal version control system, like git, though it is not ideal for data files. If you want to get a bit fancy, maybe look at dat (https://datproject.org/).
Keep all versions of the data files, so that if something gets corrupted (e.g., you acci- dentally type over some of the data and don’t notice it until much later), you will be able to go back and fix it. Before you start inserting more data, make a copy of the file with a new version number: file v1.xlsx, file v2.xlsx, . . .
When you are not actively entering data, and particularly when you are done entering data, write-protect the file. That way, you won’t accidentally change things.
• On a Mac, right-click on the file in Finder and select “Get Info”. In the menu that opens, there is a section at the bottom on “Sharing & Permissions”. Click on “Privilege” for yourself and select “Read only”.
• In Windows, right-click on the file in Windows Explorer and select “Properties”. In the “General” tab, there is a section at the bottom with “Attributes”. Select the box for “Read-only” and click the “OK” button.

### Formato

Keep a copy of your data files in a plain text format, with comma or tab delimiters. We generally use comma-delimited (CSV) files. The spreadsheet in Figure 11A would be saved as a plain text file with commas separating the fields, as in Figure 11B.

The CSV format is not pretty to look at, but you can open the file in Excel or another spreadsheet program and view it in the standard way. More importantly, this sort of non- proprietary file format does not and never will require any sort of special software. And CSV files are easier to handle in code.
If any of the cells in your data include commas, Excel will put double-quotes around the contents of each cell when it is saved in CSV format. That requires slightly more finesse to deal with, but it is generally not a concern.

Controle de qualidade dos dados

This is true regardless of whether you plan to share the data, because quality control will make it eas- ier to analyze your own data and decrease the chance of making mistakes. However, it is particularly important for data that will be shared because scientists using the data will not be familiar with quirks in the data and how to work around them.

- If a column should contain numeric values, check that there are no non-numeric values in the data.

- Check that empty cells actually represent missing
data, and not mistakes in data entry, and indicate that they are empty using the appropriate null values (see recommendation 6).
-  Check for consistency in unit of measurement, data type (e.g., numeric, character), naming scheme (e.g., taxonomy, location), etc.

### Depósito

When choosing a repository you should consider where other researchers in your discipline are sharing their data. This helps to quickly identify the commun- ity's standard approach to sharing and increases the likelihood that other scientists will discover your data. In particular, if there is a centralized repository for a specific kind of data (e.g., GenBank for sequence data) then it should be used.

Most repositories will describe how this works, but an easy way to guarantee that your data are citable is to confirm that the reposit- ory associates it with a persistent identifier, the most popular of which is the digital object identifier (DOI). DOIs are permanent unique identifiers that are indep- endent of physical location and site ownership. 
- GitHub
- Figshare
- Open Science Framework

### Licença

Including an explicit license with your data is the best way to let others know exactly what they can and cannot do with the data you shared. Following the Panton Principles http://pantonprinciples.org we recom- mend:
1. Using well established licenses (or waivers) in order to clearly communicate the rights and resp- onsibilities of both the people providing the data and the people using it.
2. Using the most open license (or waiver) possible, because even minor restrictions on data use can have unintended consequences for the reuse of the data (Schofield et al. 2009, Poisot et al. 2013).


## Criando um compendium

### Estrutura

- simples arquivo R comentado
- Arquivo Rmd (texto, dados e saídas)

Exemplo

| - DESCRIPTION     # Metadados do projeto e dependências
| - LICENSE
| - README.md       # Descrição do conteúodo e guia para usuários
| - data/           # dados originais quando criados e nao modificaos
|   +- my_data.csv  # arquivo de dados em formatos abertos  (CSV)
| - analysis/       # qualquer código da análise
|   +- my_scripts.R # Código R usado para analisar e visualizar os dados
|   +- my_scripts.Rmd


### RMarkdown


